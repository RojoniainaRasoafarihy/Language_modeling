# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uqtdvmcdq-HjTFj6-KAk6zNZSOX92h9O
"""

from model_utils import load_model_and_tokenizer
from data_preparation import prepare_data
from config import initialize_wandb, setup_training_args
from trainer import GPT2TrainerHF

if __name__ == "__main__":
    # Initialisation
    model_name = "gpt2"
    project_name = "GPT2-HF-Training"
    dataset_path = "/content/rakitra.csv"

    # Initialisation de Weights & Biases
    initialize_wandb(project_name)

    # Charger le modèle et le tokenizer
    model, tokenizer = load_model_and_tokenizer(model_name)

    # Préparation des données
    tokenized_train, tokenized_eval = prepare_data(tokenizer, dataset_path, block_size=128)

    # Configuration des arguments d'entraînement
    training_args = setup_training_args(output_dir="gpt2_results", epochs=3, batch_size=8)

    # Création de l'entraîneur
    trainer = GPT2TrainerHF(model, tokenizer)

    # Entraînement du modèle
    trainer.train(tokenized_train, tokenized_eval, training_args)